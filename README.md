<!-- =========================== -->
<!-- Francesco Maiomascio README -->
<!-- =========================== -->

I design and study **runtime architectures for AI-enabled systems**, with a focus on what happens *after inference*: execution, state persistence, failure, recovery, and long-term governability.

Rather than treating intelligence as a model capability or a prompt-driven interaction, I approach it as an **executable property of long-running systems**, shaped by control planes, lifecycle management, and observable execution paths.

My work is guided by a small set of architectural constraints: **execution precedes intelligence**, authority must be explicit, state transitions must be deterministic and inspectable, and inference must remain strictly separated from control. I am interested in systems that operate continuously, accumulate responsibility over time, and remain correct under failure, evolution, and scale.

<p align="center">
  <img src="https://readme-typing-svg.demolab.com?font=JetBrains+Mono&size=26&pause=1400&center=true&vCenter=true&width=620&lines=Execution+is+a+first-class+concern.;Inference+is+not+control.;State+defines+behavior+over+time." alt="Typing intro" />
</p>

## ICE â€” Intelligent Cognitive Ecosystem

ICE is a research effort centered on a precise question: *what does it mean to reliably run intelligent systems over time?*

In this context, **intelligent** and **cognitive** are not synonyms.   
*Intelligent* refers to a systemâ€™s ability to act toward goals under constraints.   
*Cognitive* refers to how that behavior persists: how state is accumulated, validated, authorized, and governed across execution.

ICE focuses on the space where the two intersect, treating **intelligence as something that is run**, not invoked.   
The emphasis is not on models or isolated agents, but on *after-inference dynamics*: runtimes, orchestration layers, execution control, authority, memory, and observability.

The term *ecosystem* reflects this scope. ICE studies how engines, agents, protocols, and orchestration strategies interact, and how behavior remains inspectable and governable as architectures evolve and systems scale.

As AI systems grow more complex, control can no longer be assumed by default. ICE exists to study how intelligent behavior can remain reliable under change.


ðŸ“˜ Docs  
https://francescomaiomascio.github.io/ice-docs/  

<p align="center">
  <img
    src="https://github-readme-activity-graph.vercel.app/graph?username=francescomaiomascio&theme=react-dark&hide_border=true&area=true"
    width="95%"
  />
</p>

This is independent, long-term research.

You can support the work below.

<p align="center">
  <a href="https://www.buymeacoffee.com/francescomaiomascio">
    <img
      src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png"
      height="52"
      alt="Buy Me a Coffee"
    />
  </a>
</p>




